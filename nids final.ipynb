{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47e97456",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ravi choudary\\AppData\\Local\\Temp\\ipykernel_2696\\446845706.py:52: DtypeWarning: Columns (0,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(dataset_path, names=column_names, header=None)\n",
      "C:\\Users\\Ravi choudary\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected Intrusions:\n",
      "Source IP: 192.168.1.50, Destination IP: 10.0.0.50, Detection Type: Anomaly-based attack, Payload: Anomalous data point\n",
      "Source IP: 192.168.1.96, Destination IP: 10.0.0.96, Detection Type: Anomaly-based attack, Payload: Anomalous data point\n",
      "Source IP: 192.168.1.117, Destination IP: 10.0.0.117, Detection Type: Anomaly-based attack, Payload: Anomalous data point\n",
      "Source IP: 192.168.1.119, Destination IP: 10.0.0.119, Detection Type: Anomaly-based attack, Payload: Anomalous data point\n",
      "Source IP: 192.168.1.127, Destination IP: 10.0.0.127, Detection Type: Anomaly-based attack, Payload: Anomalous data point\n",
      "Source IP: 192.168.1.144, Destination IP: 10.0.0.144, Detection Type: Anomaly-based attack, Payload: Anomalous data point\n",
      "Source IP: 192.168.1.218, Destination IP: 10.0.0.218, Detection Type: Anomaly-based attack, Payload: Anomalous data point\n",
      "Source IP: 192.168.1.36, Destination IP: 10.0.0.36, Detection Type: Anomaly-based attack, Payload: Anomalous data point\n",
      "Source IP: 192.168.1.38, Destination IP: 10.0.0.38, Detection Type: Anomaly-based attack, Payload: Anomalous data point\n",
      "Source IP: 192.168.1.53, Destination IP: 10.0.0.53, Detection Type: Anomaly-based attack, Payload: Anomalous data point\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import re\n",
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "import os\n",
    "import json\n",
    "\n",
    "# File to store detected anomalies\n",
    "STORED_ANOMALIES_FILE = \"stored_anomalies.json\"\n",
    "\n",
    "# Load stored anomalies if available\n",
    "def load_stored_anomalies():\n",
    "    if os.path.exists(STORED_ANOMALIES_FILE):\n",
    "        with open(STORED_ANOMALIES_FILE, \"r\") as file:\n",
    "            return json.load(file)\n",
    "    return []\n",
    "\n",
    "# Save new anomalies to the file\n",
    "def save_stored_anomalies(stored_anomalies):\n",
    "    with open(STORED_ANOMALIES_FILE, \"w\") as file:\n",
    "        json.dump(stored_anomalies, file, indent=4)\n",
    "\n",
    "# Load initial anomalies\n",
    "stored_anomalies = load_stored_anomalies()\n",
    "\n",
    "# Define signature patterns for detection\n",
    "SIGNATURES = [\n",
    "    r'(\\bftp\\b.*\\broot\\b)',           # Example: FTP root attempt\n",
    "    r'(\\bhttp\\b.*\\battack\\b)',        # Example: HTTP request with suspicious content\n",
    "    r'(\\bSELECT\\b.*\\bFROM\\b)',        # Common SQL data extraction pattern\n",
    "    r'(\\bDROP\\b.*\\bTABLE\\b)',         # SQL Injection pattern for table deletion\n",
    "    r'(\\b<|>|\\balert\\b|\\bscript\\b)'  # Potential XSS pattern with HTML/JavaScript\n",
    "]\n",
    "\n",
    "# Load the KDD CUP 1999 dataset (update path if necessary)\n",
    "column_names = [\n",
    "    'duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes',\n",
    "    'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins',\n",
    "    'logged_in', 'num_compromised', 'root_shell', 'su_attempted', 'num_root',\n",
    "    'num_file_creations', 'num_shells', 'num_access_files', 'num_outbound_cmds',\n",
    "    'is_host_login', 'is_guest_login', 'count', 'srv_count', 'serror_rate',\n",
    "    'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate',\n",
    "    'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count',\n",
    "    'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',\n",
    "    'dst_host_srv_diff_host_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate',\n",
    "    'dst_host_rerror_rate', 'dst_host_srv_rerror_rate', 'label'\n",
    "]\n",
    "\n",
    "dataset_path = 'kddcup.data_10_percent_corrected.csv'  # Replace with the correct path\n",
    "data = pd.read_csv(dataset_path, names=column_names, header=None)\n",
    "\n",
    "# Step 1: Signature-Based Detection\n",
    "def signature_based_detection(data, signatures):\n",
    "    detected_attacks = []\n",
    "    for index, row in data.iterrows():\n",
    "        payload = row['service']  # Update this column based on your data's structure\n",
    "        for signature in signatures:\n",
    "            if re.search(signature, payload, re.IGNORECASE):\n",
    "                detected_attacks.append({\n",
    "                    'src_ip': f\"192.168.1.{index % 255}\",  # Placeholder IP address\n",
    "                    'dst_ip': f\"10.0.0.{index % 255}\",     # Placeholder IP address\n",
    "                    'payload': payload,\n",
    "                    'attack_type': 'Signature-based attack'\n",
    "                })\n",
    "    return detected_attacks\n",
    "\n",
    "# Step 2: Anomaly-Based Detection\n",
    "def anomaly_based_detection(data):\n",
    "    # Select numerical features for anomaly detection\n",
    "    numeric_columns = ['duration', 'src_bytes', 'dst_bytes', 'count', 'srv_count']\n",
    "    \n",
    "    # Ensure numeric conversion and drop invalid rows\n",
    "    for col in numeric_columns:\n",
    "        data[col] = pd.to_numeric(data[col], errors='coerce')\n",
    "    data = data.dropna(subset=numeric_columns)\n",
    "    \n",
    "    features = data[numeric_columns].fillna(0)\n",
    "    \n",
    "    # Train the Isolation Forest model\n",
    "    isolation_forest = IsolationForest(contamination=0.1, random_state=42)\n",
    "    isolation_forest.fit(features)\n",
    "    \n",
    "    # Predict anomalies\n",
    "    predictions = isolation_forest.predict(features)\n",
    "\n",
    "    detected_anomalies = []\n",
    "    for i, prediction in enumerate(predictions):\n",
    "        if prediction == -1:\n",
    "            detected_anomalies.append({\n",
    "                'src_ip': f\"192.168.1.{i % 255}\",  # Placeholder IP address\n",
    "                'dst_ip': f\"10.0.0.{i % 255}\",     # Placeholder IP address\n",
    "                'payload': 'Anomalous data point',\n",
    "                'attack_type': 'Anomaly-based attack'\n",
    "            })\n",
    "    return detected_anomalies\n",
    "\n",
    "# Step 3: Popup Alert Function\n",
    "def show_popup(alert_message):\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()  # Hide the main tkinter window\n",
    "    messagebox.showwarning(\"Threat Detected\", alert_message)\n",
    "    root.destroy()  # Properly destroy the Tkinter instance after showing\n",
    "\n",
    "# Step 4: Combine detection methods and show alerts\n",
    "def detect_intrusions(data, signatures):\n",
    "    global stored_anomalies\n",
    "    signature_attacks = signature_based_detection(data, signatures)\n",
    "    anomaly_attacks = anomaly_based_detection(data)\n",
    "\n",
    "    # Check if anomaly matches stored signatures\n",
    "    for anomaly in anomaly_attacks:\n",
    "        if anomaly['payload'] in stored_anomalies:\n",
    "            anomaly['attack_type'] = 'Signature-based attack (from stored anomalies)'\n",
    "\n",
    "    # Add new anomalies to stored signatures\n",
    "    for anomaly in anomaly_attacks:\n",
    "        if anomaly['payload'] not in stored_anomalies:\n",
    "            stored_anomalies.append(anomaly['payload'])\n",
    "\n",
    "    # Limit the total alerts to 10\n",
    "    all_attacks = (signature_attacks + anomaly_attacks)[:10]\n",
    "\n",
    "    # Show popups for the limited attacks\n",
    "    for attack in all_attacks:\n",
    "        alert_message = (\n",
    "            f\"Attack Detected!\\n\"\n",
    "            f\"Source IP: {attack['src_ip']}\\n\"\n",
    "            f\"Destination IP: {attack['dst_ip']}\\n\"\n",
    "            f\"Detection Type: {attack['attack_type']}\\n\"\n",
    "            f\"Payload: {attack['payload']}\"\n",
    "        )\n",
    "        show_popup(alert_message)\n",
    "\n",
    "    return all_attacks\n",
    "\n",
    "# Step 5: Run the detection process\n",
    "detected_intrusions = detect_intrusions(data, SIGNATURES)\n",
    "\n",
    "# Save the updated stored anomalies\n",
    "save_stored_anomalies(stored_anomalies)\n",
    "\n",
    "# Print detected intrusions to the console for verification (optional)\n",
    "if detected_intrusions:\n",
    "    print(\"Detected Intrusions:\")\n",
    "    for intrusion in detected_intrusions:\n",
    "        print(\n",
    "            f\"Source IP: {intrusion['src_ip']}, \"\n",
    "            f\"Destination IP: {intrusion['dst_ip']}, \"\n",
    "            f\"Detection Type: {intrusion['attack_type']}, \"\n",
    "            f\"Payload: {intrusion['payload']}\"\n",
    "        )\n",
    "else:\n",
    "    print(\"No intrusions detected.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "281b9513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeba06b33d97465aaa5b2dfb2a3d70f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Upload your dataset (CSV):'), FileUpload(value={}, accept='.csv', description='Uplâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import io\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# File to store detected anomalies\n",
    "STORED_ANOMALIES_FILE = \"stored_anomalies.json\"\n",
    "\n",
    "# Load stored anomalies if available\n",
    "def load_stored_anomalies():\n",
    "    if os.path.exists(STORED_ANOMALIES_FILE):\n",
    "        with open(STORED_ANOMALIES_FILE, \"r\") as file:\n",
    "            return json.load(file)\n",
    "    return []\n",
    "\n",
    "# Save new anomalies to the file\n",
    "def save_stored_anomalies(stored_anomalies):\n",
    "    with open(STORED_ANOMALIES_FILE, \"w\") as file:\n",
    "        json.dump(stored_anomalies, file, indent=4)\n",
    "\n",
    "# Load initial anomalies\n",
    "stored_anomalies = load_stored_anomalies()\n",
    "\n",
    "# Define signature patterns for detection\n",
    "SIGNATURES = [\n",
    "    r'(\\bftp\\b.*\\broot\\b)',           # Example: FTP root attempt\n",
    "    r'(\\bhttp\\b.*\\battack\\b)',        # Example: HTTP request with suspicious content\n",
    "    r'(\\bSELECT\\b.*\\bFROM\\b)',        # Common SQL data extraction pattern\n",
    "    r'(\\bDROP\\b.*\\bTABLE\\b)',         # SQL Injection pattern for table deletion\n",
    "    r'(\\b<|>|\\balert\\b|\\bscript\\b)'  # Potential XSS pattern with HTML/JavaScript\n",
    "]\n",
    "\n",
    "# Step 1: Signature-Based Detection\n",
    "def signature_based_detection(data, signatures):\n",
    "    detected_attacks = []\n",
    "    for index, row in data.iterrows():\n",
    "        payload = row['service']  # Update this column based on your data's structure\n",
    "        for signature in signatures:\n",
    "            if re.search(signature, payload, re.IGNORECASE):\n",
    "                detected_attacks.append({\n",
    "                    'src_ip': f\"192.168.1.{index % 255}\",  # Placeholder IP address\n",
    "                    'dst_ip': f\"10.0.0.{index % 255}\",     # Placeholder IP address\n",
    "                    'payload': payload,\n",
    "                    'attack_type': 'Signature-based attack'\n",
    "                })\n",
    "    return detected_attacks\n",
    "\n",
    "# Step 2: Anomaly-Based Detection\n",
    "def anomaly_based_detection(data):\n",
    "    # Select numerical features for anomaly detection\n",
    "    numeric_columns = ['duration', 'src_bytes', 'dst_bytes', 'count', 'srv_count']\n",
    "    \n",
    "    # Ensure numeric conversion and drop invalid rows\n",
    "    for col in numeric_columns:\n",
    "        data[col] = pd.to_numeric(data[col], errors='coerce')\n",
    "    data = data.dropna(subset=numeric_columns)\n",
    "    \n",
    "    features = data[numeric_columns].fillna(0)\n",
    "    \n",
    "    # Train the Isolation Forest model\n",
    "    isolation_forest = IsolationForest(contamination=0.1, random_state=42)\n",
    "    isolation_forest.fit(features)\n",
    "    \n",
    "    # Predict anomalies\n",
    "    predictions = isolation_forest.predict(features)\n",
    "\n",
    "    detected_anomalies = []\n",
    "    for i, prediction in enumerate(predictions):\n",
    "        if prediction == -1:\n",
    "            detected_anomalies.append({\n",
    "                'src_ip': f\"192.168.1.{i % 255}\",  # Placeholder IP address\n",
    "                'dst_ip': f\"10.0.0.{i % 255}\",     # Placeholder IP address\n",
    "                'payload': 'Anomalous data point',\n",
    "                'attack_type': 'Anomaly-based attack'\n",
    "            })\n",
    "    return detected_anomalies\n",
    "\n",
    "# Step 3: Combine detection methods and display alerts\n",
    "def detect_intrusions(data, signatures):\n",
    "    global stored_anomalies\n",
    "    signature_attacks = signature_based_detection(data, signatures)\n",
    "    anomaly_attacks = anomaly_based_detection(data)\n",
    "\n",
    "    # Check if anomaly matches stored signatures\n",
    "    for anomaly in anomaly_attacks:\n",
    "        if anomaly['payload'] in stored_anomalies:\n",
    "            anomaly['attack_type'] = 'Signature-based attack (from stored anomalies)'\n",
    "\n",
    "    # Add new anomalies to stored signatures\n",
    "    for anomaly in anomaly_attacks:\n",
    "        if anomaly['payload'] not in stored_anomalies:\n",
    "            stored_anomalies.append(anomaly['payload'])\n",
    "\n",
    "    # Limit the total alerts to 10\n",
    "    all_attacks = (signature_attacks + anomaly_attacks)[:10]\n",
    "\n",
    "    # Save anomalies\n",
    "    save_stored_anomalies(stored_anomalies)\n",
    "\n",
    "    return all_attacks\n",
    "\n",
    "# Step 4: User Interface using ipywidgets\n",
    "def start_interface():\n",
    "    # Create widgets\n",
    "    file_upload = widgets.FileUpload(accept='.csv', multiple=False)\n",
    "    run_button = widgets.Button(description=\"Run Detection\")\n",
    "    output_area = widgets.Output()\n",
    "    \n",
    "    # Define button click handler\n",
    "    def on_run_button_clicked(b):\n",
    "        with output_area:\n",
    "            clear_output()\n",
    "            if file_upload.value:\n",
    "                # Load the uploaded file\n",
    "                uploaded_file = list(file_upload.value.values())[0]\n",
    "                data = pd.read_csv(io.BytesIO(uploaded_file['content']), header=None)\n",
    "                data.columns = [\n",
    "                    'duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes',\n",
    "                    'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins',\n",
    "                    'logged_in', 'num_compromised', 'root_shell', 'su_attempted', 'num_root',\n",
    "                    'num_file_creations', 'num_shells', 'num_access_files', 'num_outbound_cmds',\n",
    "                    'is_host_login', 'is_guest_login', 'count', 'srv_count', 'serror_rate',\n",
    "                    'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate',\n",
    "                    'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count',\n",
    "                    'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',\n",
    "                    'dst_host_srv_diff_host_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate',\n",
    "                    'dst_host_rerror_rate', 'dst_host_srv_rerror_rate', 'label'\n",
    "                ]\n",
    "\n",
    "                # Run intrusion detection\n",
    "                intrusions = detect_intrusions(data, SIGNATURES)\n",
    "                \n",
    "                # Display results\n",
    "                if intrusions:\n",
    "                    print(\"Detected Intrusions:\")\n",
    "                    for intrusion in intrusions:\n",
    "                        print(\n",
    "                            f\"Source IP: {intrusion['src_ip']}, \"\n",
    "                            f\"Destination IP: {intrusion['dst_ip']}, \"\n",
    "                            f\"Detection Type: {intrusion['attack_type']}, \"\n",
    "                            f\"Payload: {intrusion['payload']}\"\n",
    "                        )\n",
    "                else:\n",
    "                    print(\"No intrusions detected.\")\n",
    "            else:\n",
    "                print(\"Please upload a dataset file to run detection.\")\n",
    "\n",
    "    # Attach the handler to the button\n",
    "    run_button.on_click(on_run_button_clicked)\n",
    "\n",
    "    # Display widgets\n",
    "    display(widgets.VBox([widgets.Label(\"Upload your dataset (CSV):\"), file_upload, run_button, output_area]))\n",
    "\n",
    "# Start the interface\n",
    "start_interface()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14846c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlit\n",
      "  Downloading streamlit-1.41.0-py2.py3-none-any.whl (23.4 MB)\n",
      "     ---------------------------------------- 23.4/23.4 MB 3.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging<25,>=20 in c:\\users\\ravi choudary\\anaconda3\\lib\\site-packages (from streamlit) (21.3)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in c:\\users\\ravi choudary\\anaconda3\\lib\\site-packages (from streamlit) (9.2.0)\n",
      "Collecting cachetools<6,>=4.0\n",
      "  Downloading cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
      "Collecting pyarrow>=7.0\n",
      "  Downloading pyarrow-18.1.0-cp39-cp39-win_amd64.whl (25.3 MB)\n",
      "     ---------------------------------------- 25.3/25.3 MB 3.7 MB/s eta 0:00:00\n",
      "Collecting altair<6,>=4.0\n",
      "  Downloading altair-5.5.0-py3-none-any.whl (731 kB)\n",
      "     -------------------------------------- 731.2/731.2 kB 6.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in c:\\users\\ravi choudary\\anaconda3\\lib\\site-packages (from streamlit) (4.3.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in c:\\users\\ravi choudary\\anaconda3\\lib\\site-packages (from streamlit) (4.25.3)\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7\n",
      "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
      "     ------------------------------------- 207.3/207.3 kB 13.1 MB/s eta 0:00:00\n",
      "Collecting tenacity<10,>=8.1.0\n",
      "  Downloading tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Collecting pydeck<1,>=0.8.0b4\n",
      "  Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "     ---------------------------------------- 6.9/6.9 MB 4.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\ravi choudary\\anaconda3\\lib\\site-packages (from streamlit) (8.0.4)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in c:\\users\\ravi choudary\\anaconda3\\lib\\site-packages (from streamlit) (2.1.6)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\ravi choudary\\anaconda3\\lib\\site-packages (from streamlit) (2.28.1)\n",
      "Collecting blinker<2,>=1.0.0\n",
      "  Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\ravi choudary\\anaconda3\\lib\\site-packages (from streamlit) (6.1)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in c:\\users\\ravi choudary\\anaconda3\\lib\\site-packages (from streamlit) (1.24.4)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in c:\\users\\ravi choudary\\anaconda3\\lib\\site-packages (from streamlit) (13.7.1)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\ravi choudary\\anaconda3\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in c:\\users\\ravi choudary\\anaconda3\\lib\\site-packages (from streamlit) (1.4.4)\n",
      "Collecting narwhals>=1.14.2\n",
      "  Downloading narwhals-1.18.2-py3-none-any.whl (250 kB)\n",
      "     -------------------------------------- 250.2/250.2 kB 7.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ravi choudary\\anaconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit) (2.11.3)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\ravi choudary\\anaconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit) (4.16.0)\n",
      "Collecting typing-extensions<5,>=4.3.0\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\ravi choudary\\anaconda3\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.5)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "     ---------------------------------------- 62.7/62.7 kB ? eta 0:00:00\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\ravi choudary\\anaconda3\\lib\\site-packages (from packaging<25,>=20->streamlit) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\ravi choudary\\anaconda3\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ravi choudary\\anaconda3\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2022.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ravi choudary\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ravi choudary\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ravi choudary\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\ravi choudary\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.0.4)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\ravi choudary\\anaconda3\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (2.17.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\ravi choudary\\anaconda3\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\ravi choudary\\anaconda3\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.0.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\ravi choudary\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (21.4.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\ravi choudary\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\ravi choudary\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ravi choudary\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas<3,>=1.4.0->streamlit) (1.16.0)\n",
      "Installing collected packages: typing-extensions, tenacity, smmap, pyarrow, narwhals, cachetools, blinker, pydeck, gitdb, altair, gitpython, streamlit\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.3.0\n",
      "    Uninstalling typing_extensions-4.3.0:\n",
      "      Successfully uninstalled typing_extensions-4.3.0\n",
      "  Attempting uninstall: tenacity\n",
      "    Found existing installation: tenacity 8.0.1\n",
      "    Uninstalling tenacity-8.0.1:\n",
      "      Successfully uninstalled tenacity-8.0.1\n",
      "Successfully installed altair-5.5.0 blinker-1.9.0 cachetools-5.5.0 gitdb-4.0.11 gitpython-3.1.43 narwhals-1.18.2 pyarrow-18.1.0 pydeck-0.9.1 smmap-5.0.1 streamlit-1.41.0 tenacity-9.0.0 typing-extensions-4.12.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install streamlit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8a042aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-13 21:49:20.898 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-13 21:49:21.261 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\Ravi choudary\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2024-12-13 21:49:21.262 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-13 21:49:21.263 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-13 21:49:21.264 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-13 21:49:21.266 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-13 21:49:21.267 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-13 21:49:21.269 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-13 21:49:21.271 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-13 21:49:21.273 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-13 21:49:21.274 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-13 21:49:21.276 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import streamlit as st\n",
    "from io import StringIO\n",
    "\n",
    "# File to store detected anomalies\n",
    "STORED_ANOMALIES_FILE = \"stored_anomalies.json\"\n",
    "\n",
    "# Load stored anomalies if available\n",
    "def load_stored_anomalies():\n",
    "    if os.path.exists(STORED_ANOMALIES_FILE):\n",
    "        with open(STORED_ANOMALIES_FILE, \"r\") as file:\n",
    "            return json.load(file)\n",
    "    return []\n",
    "\n",
    "# Save new anomalies to the file\n",
    "def save_stored_anomalies(stored_anomalies):\n",
    "    with open(STORED_ANOMALIES_FILE, \"w\") as file:\n",
    "        json.dump(stored_anomalies, file, indent=4)\n",
    "\n",
    "# Load initial anomalies\n",
    "stored_anomalies = load_stored_anomalies()\n",
    "\n",
    "# Define signature patterns for detection\n",
    "SIGNATURES = [\n",
    "    r'(\\bftp\\b.*\\broot\\b)',           # Example: FTP root attempt\n",
    "    r'(\\bhttp\\b.*\\battack\\b)',        # Example: HTTP request with suspicious content\n",
    "    r'(\\bSELECT\\b.*\\bFROM\\b)',        # Common SQL data extraction pattern\n",
    "    r'(\\bDROP\\b.*\\bTABLE\\b)',         # SQL Injection pattern for table deletion\n",
    "    r'(\\b<|>|\\balert\\b|\\bscript\\b)'   # Potential XSS pattern with HTML/JavaScript\n",
    "]\n",
    "\n",
    "# Load the KDD CUP 1999 dataset (replace with correct path)\n",
    "column_names = [\n",
    "    'duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes',\n",
    "    'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins',\n",
    "    'logged_in', 'num_compromised', 'root_shell', 'su_attempted', 'num_root',\n",
    "    'num_file_creations', 'num_shells', 'num_access_files', 'num_outbound_cmds',\n",
    "    'is_host_login', 'is_guest_login', 'count', 'srv_count', 'serror_rate',\n",
    "    'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate',\n",
    "    'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count',\n",
    "    'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',\n",
    "    'dst_host_srv_diff_host_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate',\n",
    "    'dst_host_rerror_rate', 'dst_host_srv_rerror_rate', 'label'\n",
    "]\n",
    "\n",
    "# Step 1: Signature-Based Detection\n",
    "def signature_based_detection(data, signatures):\n",
    "    detected_attacks = []\n",
    "    for index, row in data.iterrows():\n",
    "        payload = row['service']  # Update this column based on your data's structure\n",
    "        for signature in signatures:\n",
    "            if re.search(signature, payload, re.IGNORECASE):\n",
    "                detected_attacks.append({\n",
    "                    'src_ip': f\"192.168.1.{index % 255}\",  # Placeholder IP address\n",
    "                    'dst_ip': f\"10.0.0.{index % 255}\",     # Placeholder IP address\n",
    "                    'payload': payload,\n",
    "                    'attack_type': 'Signature-based attack'\n",
    "                })\n",
    "    return detected_attacks\n",
    "\n",
    "# Step 2: Anomaly-Based Detection\n",
    "def anomaly_based_detection(data):\n",
    "    # Select numerical features for anomaly detection\n",
    "    numeric_columns = ['duration', 'src_bytes', 'dst_bytes', 'count', 'srv_count']\n",
    "    \n",
    "    # Ensure numeric conversion and drop invalid rows\n",
    "    for col in numeric_columns:\n",
    "        data[col] = pd.to_numeric(data[col], errors='coerce')\n",
    "    data = data.dropna(subset=numeric_columns)\n",
    "    \n",
    "    features = data[numeric_columns].fillna(0)\n",
    "    \n",
    "    # Train the Isolation Forest model\n",
    "    isolation_forest = IsolationForest(contamination=0.1, random_state=42)\n",
    "    isolation_forest.fit(features)\n",
    "    \n",
    "    # Predict anomalies\n",
    "    predictions = isolation_forest.predict(features)\n",
    "\n",
    "    detected_anomalies = []\n",
    "    for i, prediction in enumerate(predictions):\n",
    "        if prediction == -1:\n",
    "            detected_anomalies.append({\n",
    "                'src_ip': f\"192.168.1.{i % 255}\",  # Placeholder IP address\n",
    "                'dst_ip': f\"10.0.0.{i % 255}\",     # Placeholder IP address\n",
    "                'payload': 'Anomalous data point',\n",
    "                'attack_type': 'Anomaly-based attack'\n",
    "            })\n",
    "    return detected_anomalies\n",
    "\n",
    "# Step 4: Combine detection methods\n",
    "def detect_intrusions(data, signatures):\n",
    "    global stored_anomalies\n",
    "    signature_attacks = signature_based_detection(data, signatures)\n",
    "    anomaly_attacks = anomaly_based_detection(data)\n",
    "\n",
    "    # Check if anomaly matches stored signatures\n",
    "    for anomaly in anomaly_attacks:\n",
    "        if anomaly['payload'] in stored_anomalies:\n",
    "            anomaly['attack_type'] = 'Signature-based attack (from stored anomalies)'\n",
    "\n",
    "    # Add new anomalies to stored signatures\n",
    "    for anomaly in anomaly_attacks:\n",
    "        if anomaly['payload'] not in stored_anomalies:\n",
    "            stored_anomalies.append(anomaly['payload'])\n",
    "\n",
    "    # Limit the total alerts to 10\n",
    "    all_attacks = (signature_attacks + anomaly_attacks)[:10]\n",
    "    \n",
    "    return all_attacks\n",
    "\n",
    "# Streamlit interface\n",
    "st.title(\"Intrusion Detection System\")\n",
    "\n",
    "# File uploader for dataset\n",
    "uploaded_file = st.file_uploader(\"Upload Dataset (CSV)\", type=[\"csv\"])\n",
    "\n",
    "if uploaded_file is not None:\n",
    "    # Read and display the dataset\n",
    "    data = pd.read_csv(uploaded_file)\n",
    "    st.write(\"Dataset Loaded:\")\n",
    "    st.dataframe(data.head())\n",
    "\n",
    "    # Button to run intrusion detection\n",
    "    if st.button(\"Detect Intrusions\"):\n",
    "        detected_intrusions = detect_intrusions(data, SIGNATURES)\n",
    "\n",
    "        # Display the results\n",
    "        if detected_intrusions:\n",
    "            st.subheader(\"Detected Intrusions:\")\n",
    "            for intrusion in detected_intrusions:\n",
    "                st.write(\n",
    "                    f\"Source IP: {intrusion['src_ip']}, \"\n",
    "                    f\"Destination IP: {intrusion['dst_ip']}, \"\n",
    "                    f\"Detection Type: {intrusion['attack_type']}, \"\n",
    "                    f\"Payload: {intrusion['payload']}\"\n",
    "                )\n",
    "        else:\n",
    "            st.write(\"No intrusions detected.\")\n",
    "\n",
    "        # Save the updated stored anomalies\n",
    "        save_stored_anomalies(stored_anomalies)\n",
    "else:\n",
    "    st.write(\"Please upload a dataset to start.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99276158",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1090521028.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Ravi choudary\\AppData\\Local\\Temp\\ipykernel_2696\\1090521028.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    streamlit run intrusin,pu\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "streamlit run intrusin,pu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e43e2066",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2841047790.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Ravi choudary\\AppData\\Local\\Temp\\ipykernel_2696\\2841047790.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    streamlit run intrusin.py\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "streamlit run intrusin.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2fedeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ravi choudary\\AppData\\Local\\Temp\\ipykernel_2696\\2573057677.py:53: DtypeWarning: Columns (0,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(dataset_path, names=column_names, header=None)\n",
      "C:\\Users\\Ravi choudary\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "import os\n",
    "import json\n",
    "\n",
    "# File to store detected anomalies\n",
    "STORED_ANOMALIES_FILE = \"stored_anomalies.json\"\n",
    "\n",
    "# Load stored anomalies if available\n",
    "def load_stored_anomalies():\n",
    "    if os.path.exists(STORED_ANOMALIES_FILE):\n",
    "        with open(STORED_ANOMALIES_FILE, \"r\") as file:\n",
    "            return json.load(file)\n",
    "    return []\n",
    "\n",
    "# Save new anomalies to the file\n",
    "def save_stored_anomalies(stored_anomalies):\n",
    "    with open(STORED_ANOMALIES_FILE, \"w\") as file:\n",
    "        json.dump(stored_anomalies, file, indent=4)\n",
    "\n",
    "# Load initial anomalies\n",
    "stored_anomalies = load_stored_anomalies()\n",
    "\n",
    "# Define signature patterns for detection\n",
    "SIGNATURES = [\n",
    "    r'(\\bftp\\b.*\\broot\\b)',           # Example: FTP root attempt\n",
    "    r'(\\bhttp\\b.*\\battack\\b)',        # Example: HTTP request with suspicious content\n",
    "    r'(\\bSELECT\\b.*\\bFROM\\b)',        # Common SQL data extraction pattern\n",
    "    r'(\\bDROP\\b.*\\bTABLE\\b)',         # SQL Injection pattern for table deletion\n",
    "    r'(\\b<|>|\\balert\\b|\\bscript\\b)'   # Potential XSS pattern with HTML/JavaScript\n",
    "]\n",
    "\n",
    "# Load the KDD CUP 1999 dataset (update path if necessary)\n",
    "column_names = [\n",
    "    'duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes',\n",
    "    'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins',\n",
    "    'logged_in', 'num_compromised', 'root_shell', 'su_attempted', 'num_root',\n",
    "    'num_file_creations', 'num_shells', 'num_access_files', 'num_outbound_cmds',\n",
    "    'is_host_login', 'is_guest_login', 'count', 'srv_count', 'serror_rate',\n",
    "    'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate',\n",
    "    'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count',\n",
    "    'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',\n",
    "    'dst_host_srv_diff_host_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate',\n",
    "    'dst_host_rerror_rate', 'dst_host_srv_rerror_rate', 'label'\n",
    "]\n",
    "\n",
    "dataset_path = 'kddcup.data_10_percent_corrected.csv'  # Replace with the correct path\n",
    "data = pd.read_csv(dataset_path, names=column_names, header=None)\n",
    "\n",
    "# Step 1: Signature-Based Detection\n",
    "def signature_based_detection(data, signatures):\n",
    "    detected_attacks = []\n",
    "    for index, row in data.iterrows():\n",
    "        payload = row['service']  # Update this column based on your data's structure\n",
    "        for signature in signatures:\n",
    "            if re.search(signature, payload, re.IGNORECASE):\n",
    "                detected_attacks.append({\n",
    "                    'src_ip': f\"192.168.1.{index % 255}\",  # Placeholder IP address\n",
    "                    'dst_ip': f\"10.0.0.{index % 255}\",     # Placeholder IP address\n",
    "                    'payload': payload,\n",
    "                    'attack_type': 'Signature-based attack'\n",
    "                })\n",
    "    return detected_attacks\n",
    "\n",
    "# Step 2: Anomaly-Based Detection\n",
    "def anomaly_based_detection(train_data, test_data):\n",
    "    # Select numerical features for anomaly detection\n",
    "    numeric_columns = ['duration', 'src_bytes', 'dst_bytes', 'count', 'srv_count']\n",
    "    \n",
    "    # Ensure numeric conversion and drop invalid rows for training and testing data\n",
    "    for col in numeric_columns:\n",
    "        train_data[col] = pd.to_numeric(train_data[col], errors='coerce')\n",
    "        test_data[col] = pd.to_numeric(test_data[col], errors='coerce')\n",
    "        \n",
    "    train_data = train_data.dropna(subset=numeric_columns)\n",
    "    test_data = test_data.dropna(subset=numeric_columns)\n",
    "    \n",
    "    # Features for training and testing\n",
    "    X_train = train_data[numeric_columns].fillna(0)\n",
    "    X_test = test_data[numeric_columns].fillna(0)\n",
    "    \n",
    "    # Train the Isolation Forest model on the training data\n",
    "    isolation_forest = IsolationForest(contamination=0.1, random_state=42)\n",
    "    isolation_forest.fit(X_train)\n",
    "    \n",
    "    # Predict anomalies on the test data\n",
    "    predictions = isolation_forest.predict(X_test)\n",
    "\n",
    "    detected_anomalies = []\n",
    "    for i, prediction in enumerate(predictions):\n",
    "        if prediction == -1:  # Anomaly detected\n",
    "            detected_anomalies.append({\n",
    "                'src_ip': f\"192.168.1.{i % 255}\",  # Placeholder IP address\n",
    "                'dst_ip': f\"10.0.0.{i % 255}\",     # Placeholder IP address\n",
    "                'payload': 'Anomalous data point',\n",
    "                'attack_type': 'Anomaly-based attack'\n",
    "            })\n",
    "    return detected_anomalies\n",
    "\n",
    "# Step 3: Popup Alert Function\n",
    "def show_popup(alert_message):\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()  # Hide the main tkinter window\n",
    "    messagebox.showwarning(\"Threat Detected\", alert_message)\n",
    "    root.destroy()  # Properly destroy the Tkinter instance after showing\n",
    "\n",
    "# Step 4: Combine detection methods and show alerts\n",
    "def detect_intrusions(data, signatures):\n",
    "    global stored_anomalies\n",
    "    signature_attacks = signature_based_detection(data, signatures)\n",
    "\n",
    "    # Step 5: Split the data into training and testing sets (80% for training, 20% for testing)\n",
    "    train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Step 6: Anomaly-based detection using the train and test data\n",
    "    anomaly_attacks = anomaly_based_detection(train_data, test_data)\n",
    "\n",
    "    # Check if anomaly matches stored signatures\n",
    "    for anomaly in anomaly_attacks:\n",
    "        if anomaly['payload'] in stored_anomalies:\n",
    "            anomaly['attack_type'] = 'Signature-based attack (from stored anomalies)'\n",
    "\n",
    "    # Add new anomalies to stored signatures\n",
    "    for anomaly in anomaly_attacks:\n",
    "        if anomaly['payload'] not in stored_anomalies:\n",
    "            stored_anomalies.append(anomaly['payload'])\n",
    "\n",
    "    # Limit the total alerts to 10\n",
    "    all_attacks = (signature_attacks + anomaly_attacks)[:10]\n",
    "\n",
    "    # Show popups for the limited attacks\n",
    "    for attack in all_attacks:\n",
    "        alert_message = (\n",
    "            f\"Attack Detected!\\n\"\n",
    "            f\"Source IP: {attack['src_ip']}\\n\"\n",
    "            f\"Destination IP: {attack['dst_ip']}\\n\"\n",
    "            f\"Detection Type: {attack['attack_type']}\\n\"\n",
    "            f\"Payload: {attack['payload']}\"\n",
    "        )\n",
    "        show_popup(alert_message)\n",
    "\n",
    "    return all_attacks\n",
    "\n",
    "# Step 7: Run the detection process\n",
    "detected_intrusions = detect_intrusions(data, SIGNATURES)\n",
    "\n",
    "# Save the updated stored anomalies\n",
    "save_stored_anomalies(stored_anomalies)\n",
    "\n",
    "# Print detected intrusions to the console for verification (optional)\n",
    "if detected_intrusions:\n",
    "    print(\"Detected Intrusions:\")\n",
    "    for intrusion in detected_intrusions:\n",
    "        print(\n",
    "            f\"Source IP: {intrusion['src_ip']}, \"\n",
    "            f\"Destination IP: {intrusion['dst_ip']}, \"\n",
    "            f\"Detection Type: {intrusion['attack_type']}, \"\n",
    "            f\"Payload: {intrusion['payload']}\"\n",
    "        )\n",
    "else:\n",
    "    print(\"No intrusions detected.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fcb406",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "dtype = {\n",
    "    'duration': float,\n",
    "    'protocol_type': str,\n",
    "    'service': str,\n",
    "    'flag': str,\n",
    "    'src_bytes': float,\n",
    "    'dst_bytes': float,\n",
    "    'land': str,  # Example for non-numeric columns\n",
    "    'wrong_fragment': str,\n",
    "    # Add other columns with their respective data types\n",
    "}\n",
    "\n",
    "column_names = [\n",
    "    'duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes',\n",
    "    'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins',\n",
    "    'logged_in', 'num_compromised', 'root_shell', 'su_attempted', 'num_root',\n",
    "    'num_file_creations', 'num_shells', 'num_access_files', 'num_outbound_cmds',\n",
    "    'is_host_login', 'is_guest_login', 'count', 'srv_count', 'serror_rate',\n",
    "    'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate',\n",
    "    'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count',\n",
    "    'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',\n",
    "    'dst_host_srv_diff_host_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate',\n",
    "    'dst_host_rerror_rate', 'dst_host_srv_rerror_rate', 'label'\n",
    "]\n",
    "\n",
    "dataset_path = 'kddcup.data_10_percent_corrected.csv'  # Replace with actual path\n",
    "data = pd.read_csv(dataset_path, names=column_names, header=None, dtype=dtype, low_memory=False)\n",
    "\n",
    "# Step 2: Split the dataset into training and testing sets\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Feature Selection (numerical columns for anomaly detection)\n",
    "numeric_columns = ['duration', 'src_bytes', 'dst_bytes', 'count', 'srv_count']\n",
    "X_train = train_data[numeric_columns].fillna(0)\n",
    "X_test = test_data[numeric_columns].fillna(0)\n",
    "\n",
    "# Step 4: Initialize and Train the Isolation Forest model\n",
    "isolation_forest = IsolationForest(contamination=0.1, random_state=42)\n",
    "isolation_forest.fit(X_train)\n",
    "\n",
    "# Step 5: Make predictions on the test dataset\n",
    "predictions = isolation_forest.predict(X_test)\n",
    "\n",
    "# Convert -1 to 'Anomaly' and 1 to 'Normal' for evaluation purposes\n",
    "predictions = ['Anomaly' if p == -1 else 'Normal' for p in predictions]\n",
    "\n",
    "# Step 6: Show the training and testing datasets\n",
    "print(\"Training Data (First 5 rows):\")\n",
    "print(X_train.head())\n",
    "\n",
    "print(\"\\nTesting Data (First 5 rows):\")\n",
    "print(X_test.head())\n",
    "\n",
    "# Step 7: Evaluation (since the real anomaly labels are not available, this can be simulated)\n",
    "# Assuming we don't have ground truth labels, you could evaluate with dummy labels or use manual evaluation:\n",
    "# For demonstration, let's assume anomalies as 1 and normal as 0 (this would normally come from actual labels if available)\n",
    "\n",
    "# Here, for evaluation purposes, we'll just print the classification report and confusion matrix\n",
    "# Note: Normally, you would have a ground truth for comparison\n",
    "print(\"\\nModel Evaluation:\")\n",
    "print(classification_report(predictions, predictions))  # Here, you should replace with actual labels\n",
    "print(confusion_matrix(predictions, predictions))  # Here, you should replace with actual labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd6e0c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8884682e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   duration  protocol_type  service  flag  src_bytes  dst_bytes  land  \\\n",
      "0  duration  protocol_type  service  flag  src_bytes  dst_bytes  land   \n",
      "1         0            tcp     http    SF        181       5450     0   \n",
      "2         0            tcp     http    SF        239        486     0   \n",
      "3         0            tcp     http    SF        235       1337     0   \n",
      "4         0            tcp     http    SF        219       1337     0   \n",
      "\n",
      "   wrong_fragment  urgent  hot  ...  dst_host_srv_count  \\\n",
      "0  wrong_fragment  urgent  hot  ...  dst_host_srv_count   \n",
      "1               0       0    0  ...                   9   \n",
      "2               0       0    0  ...                  19   \n",
      "3               0       0    0  ...                  29   \n",
      "4               0       0    0  ...                  39   \n",
      "\n",
      "   dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
      "0  dst_host_same_srv_rate  dst_host_diff_srv_rate   \n",
      "1                     1.0                     0.0   \n",
      "2                     1.0                     0.0   \n",
      "3                     1.0                     0.0   \n",
      "4                     1.0                     0.0   \n",
      "\n",
      "   dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
      "0  dst_host_same_src_port_rate  dst_host_srv_diff_host_rate   \n",
      "1                         0.11                          0.0   \n",
      "2                         0.05                          0.0   \n",
      "3                         0.03                          0.0   \n",
      "4                         0.03                          0.0   \n",
      "\n",
      "   dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
      "0  dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate   \n",
      "1                   0.0                       0.0                   0.0   \n",
      "2                   0.0                       0.0                   0.0   \n",
      "3                   0.0                       0.0                   0.0   \n",
      "4                   0.0                       0.0                   0.0   \n",
      "\n",
      "   dst_host_srv_rerror_rate    label  \n",
      "0  dst_host_srv_rerror_rate    label  \n",
      "1                       0.0  normal.  \n",
      "2                       0.0  normal.  \n",
      "3                       0.0  normal.  \n",
      "4                       0.0  normal.  \n",
      "\n",
      "[5 rows x 42 columns]\n",
      "duration                       object\n",
      "protocol_type                  object\n",
      "service                        object\n",
      "flag                           object\n",
      "src_bytes                      object\n",
      "dst_bytes                      object\n",
      "land                           object\n",
      "wrong_fragment                 object\n",
      "urgent                         object\n",
      "hot                            object\n",
      "num_failed_logins              object\n",
      "logged_in                      object\n",
      "num_compromised                object\n",
      "root_shell                     object\n",
      "su_attempted                   object\n",
      "num_root                       object\n",
      "num_file_creations             object\n",
      "num_shells                     object\n",
      "num_access_files               object\n",
      "num_outbound_cmds              object\n",
      "is_host_login                  object\n",
      "is_guest_login                 object\n",
      "count                          object\n",
      "srv_count                      object\n",
      "serror_rate                    object\n",
      "srv_serror_rate                object\n",
      "rerror_rate                    object\n",
      "srv_rerror_rate                object\n",
      "same_srv_rate                  object\n",
      "diff_srv_rate                  object\n",
      "srv_diff_host_rate             object\n",
      "dst_host_count                 object\n",
      "dst_host_srv_count             object\n",
      "dst_host_same_srv_rate         object\n",
      "dst_host_diff_srv_rate         object\n",
      "dst_host_same_src_port_rate    object\n",
      "dst_host_srv_diff_host_rate    object\n",
      "dst_host_serror_rate           object\n",
      "dst_host_srv_serror_rate       object\n",
      "dst_host_rerror_rate           object\n",
      "dst_host_srv_rerror_rate       object\n",
      "label                          object\n",
      "dtype: object\n",
      "   duration  protocol_type  service  flag  src_bytes  dst_bytes  land  \\\n",
      "0       0.0  protocol_type  service  flag        0.0        0.0  land   \n",
      "1       0.0            tcp     http    SF      181.0     5450.0     0   \n",
      "2       0.0            tcp     http    SF      239.0      486.0     0   \n",
      "3       0.0            tcp     http    SF      235.0     1337.0     0   \n",
      "4       0.0            tcp     http    SF      219.0     1337.0     0   \n",
      "\n",
      "   wrong_fragment  urgent  hot  ...  dst_host_srv_count  \\\n",
      "0  wrong_fragment  urgent  hot  ...  dst_host_srv_count   \n",
      "1               0       0    0  ...                   9   \n",
      "2               0       0    0  ...                  19   \n",
      "3               0       0    0  ...                  29   \n",
      "4               0       0    0  ...                  39   \n",
      "\n",
      "   dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
      "0  dst_host_same_srv_rate  dst_host_diff_srv_rate   \n",
      "1                     1.0                     0.0   \n",
      "2                     1.0                     0.0   \n",
      "3                     1.0                     0.0   \n",
      "4                     1.0                     0.0   \n",
      "\n",
      "   dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
      "0  dst_host_same_src_port_rate  dst_host_srv_diff_host_rate   \n",
      "1                         0.11                          0.0   \n",
      "2                         0.05                          0.0   \n",
      "3                         0.03                          0.0   \n",
      "4                         0.03                          0.0   \n",
      "\n",
      "   dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
      "0  dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate   \n",
      "1                   0.0                       0.0                   0.0   \n",
      "2                   0.0                       0.0                   0.0   \n",
      "3                   0.0                       0.0                   0.0   \n",
      "4                   0.0                       0.0                   0.0   \n",
      "\n",
      "   dst_host_srv_rerror_rate    label  \n",
      "0  dst_host_srv_rerror_rate    label  \n",
      "1                       0.0  normal.  \n",
      "2                       0.0  normal.  \n",
      "3                       0.0  normal.  \n",
      "4                       0.0  normal.  \n",
      "\n",
      "[5 rows x 42 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load the dataset without specifying dtype initially to inspect the data\n",
    "dataset_path = 'kddcup.data_10_percent_corrected.csv'  # Replace with actual path\n",
    "column_names = [\n",
    "    'duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes',\n",
    "    'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins',\n",
    "    'logged_in', 'num_compromised', 'root_shell', 'su_attempted', 'num_root',\n",
    "    'num_file_creations', 'num_shells', 'num_access_files', 'num_outbound_cmds',\n",
    "    'is_host_login', 'is_guest_login', 'count', 'srv_count', 'serror_rate',\n",
    "    'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate',\n",
    "    'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count',\n",
    "    'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',\n",
    "    'dst_host_srv_diff_host_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate',\n",
    "    'dst_host_rerror_rate', 'dst_host_srv_rerror_rate', 'label'\n",
    "]\n",
    "\n",
    "# Load dataset without dtype specification\n",
    "data = pd.read_csv(dataset_path, names=column_names, header=None, low_memory=False)\n",
    "\n",
    "# Step 2: Inspect the first few rows to check for non-numeric issues\n",
    "print(data.head())\n",
    "\n",
    "# Step 3: Check data types and identify any columns that may have been incorrectly inferred as numeric\n",
    "print(data.dtypes)\n",
    "\n",
    "# Step 4: Convert numeric columns with non-numeric values to numeric (use errors='coerce' to turn invalid values to NaN)\n",
    "numeric_columns = ['duration', 'src_bytes', 'dst_bytes', 'count', 'srv_count']\n",
    "data[numeric_columns] = data[numeric_columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Step 5: Handle missing values by filling NaN values (e.g., with 0 or mean)\n",
    "data.fillna(0, inplace=True)\n",
    "\n",
    "# Step 6: Check again after cleaning\n",
    "print(data.head())\n",
    "\n",
    "# Now, you can proceed with your train-test split and model training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "96716dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ravi choudary\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data (First 5 rows):\n",
      "       duration  src_bytes  dst_bytes  count  srv_count\n",
      "61089       0.0      297.0      327.0   26.0       26.0\n",
      "40286       0.0      346.0     3694.0    6.0        7.0\n",
      "50242       0.0      208.0      393.0    8.0       13.0\n",
      "46990       0.0      148.0      427.0    1.0        2.0\n",
      "14217       0.0      310.0      336.0    9.0        9.0\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Split the dataset into training and testing sets\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Feature Selection (numerical columns for anomaly detection)\n",
    "numeric_columns = ['duration', 'src_bytes', 'dst_bytes', 'count', 'srv_count']\n",
    "X_train = train_data[numeric_columns].fillna(0)\n",
    "X_test = test_data[numeric_columns].fillna(0)\n",
    "\n",
    "# Step 4: Initialize and Train the Isolation Forest model\n",
    "isolation_forest = IsolationForest(contamination=0.1, random_state=42)\n",
    "isolation_forest.fit(X_train)\n",
    "\n",
    "# Step 5: Make predictions on the test dataset\n",
    "predictions = isolation_forest.predict(X_test)\n",
    "\n",
    "# Convert -1 to 'Anomaly' and 1 to 'Normal' for evaluation purposes\n",
    "predictions = ['Anomaly' if p == -1 else 'Normal' for p in predictions]\n",
    "\n",
    "# Step 6: Show the training and testing datasets\n",
    "print(\"Training Data (First 5 rows):\")\n",
    "print(X_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b4e57e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>count</th>\n",
       "      <th>srv_count</th>\n",
       "      <th>serror_rate</th>\n",
       "      <th>srv_serror_rate</th>\n",
       "      <th>rerror_rate</th>\n",
       "      <th>srv_rerror_rate</th>\n",
       "      <th>same_srv_rate</th>\n",
       "      <th>...</th>\n",
       "      <th>logged_in_logged_in</th>\n",
       "      <th>root_shell_0</th>\n",
       "      <th>root_shell_1</th>\n",
       "      <th>root_shell_root_shell</th>\n",
       "      <th>su_attempted_0</th>\n",
       "      <th>su_attempted_su_attempted</th>\n",
       "      <th>is_host_login_0</th>\n",
       "      <th>is_host_login_is_host_login</th>\n",
       "      <th>is_guest_login_0</th>\n",
       "      <th>is_guest_login_is_guest_login</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>64294.000000</td>\n",
       "      <td>64294.000000</td>\n",
       "      <td>6.429400e+04</td>\n",
       "      <td>64294.000000</td>\n",
       "      <td>64294.000000</td>\n",
       "      <td>64294.00000</td>\n",
       "      <td>64294.000000</td>\n",
       "      <td>64294.000000</td>\n",
       "      <td>64294.000000</td>\n",
       "      <td>64294.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>64294.000000</td>\n",
       "      <td>64294.000000</td>\n",
       "      <td>64294.00000</td>\n",
       "      <td>64294.000000</td>\n",
       "      <td>64294.000000</td>\n",
       "      <td>64294.000000</td>\n",
       "      <td>64294.000000</td>\n",
       "      <td>64294.000000</td>\n",
       "      <td>64294.000000</td>\n",
       "      <td>64294.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.266230</td>\n",
       "      <td>2084.757629</td>\n",
       "      <td>4.256075e+03</td>\n",
       "      <td>9.203907</td>\n",
       "      <td>11.691900</td>\n",
       "      <td>0.00445</td>\n",
       "      <td>0.004783</td>\n",
       "      <td>0.085368</td>\n",
       "      <td>0.087672</td>\n",
       "      <td>0.997529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.999704</td>\n",
       "      <td>0.00028</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>0.000016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>162.532963</td>\n",
       "      <td>9826.523839</td>\n",
       "      <td>1.898877e+04</td>\n",
       "      <td>13.219673</td>\n",
       "      <td>11.626554</td>\n",
       "      <td>0.05745</td>\n",
       "      <td>0.056281</td>\n",
       "      <td>0.277118</td>\n",
       "      <td>0.276203</td>\n",
       "      <td>0.045344</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003944</td>\n",
       "      <td>0.017188</td>\n",
       "      <td>0.01673</td>\n",
       "      <td>0.003944</td>\n",
       "      <td>0.003944</td>\n",
       "      <td>0.003944</td>\n",
       "      <td>0.003944</td>\n",
       "      <td>0.003944</td>\n",
       "      <td>0.003944</td>\n",
       "      <td>0.003944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>4.730000e+02</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>243.000000</td>\n",
       "      <td>1.502000e+03</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>306.000000</td>\n",
       "      <td>4.361000e+03</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>41065.000000</td>\n",
       "      <td>54540.000000</td>\n",
       "      <td>3.916592e+06</td>\n",
       "      <td>511.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           duration     src_bytes     dst_bytes         count     srv_count  \\\n",
       "count  64294.000000  64294.000000  6.429400e+04  64294.000000  64294.000000   \n",
       "mean       1.266230   2084.757629  4.256075e+03      9.203907     11.691900   \n",
       "std      162.532963   9826.523839  1.898877e+04     13.219673     11.626554   \n",
       "min        0.000000      0.000000  0.000000e+00      0.000000      0.000000   \n",
       "25%        0.000000    210.000000  4.730000e+02      2.000000      3.000000   \n",
       "50%        0.000000    243.000000  1.502000e+03      6.000000      8.000000   \n",
       "75%        0.000000    306.000000  4.361000e+03     13.000000     17.000000   \n",
       "max    41065.000000  54540.000000  3.916592e+06    511.000000    109.000000   \n",
       "\n",
       "       serror_rate  srv_serror_rate   rerror_rate  srv_rerror_rate  \\\n",
       "count  64294.00000     64294.000000  64294.000000     64294.000000   \n",
       "mean       0.00445         0.004783      0.085368         0.087672   \n",
       "std        0.05745         0.056281      0.277118         0.276203   \n",
       "min        0.00000         0.000000      0.000000         0.000000   \n",
       "25%        0.00000         0.000000      0.000000         0.000000   \n",
       "50%        0.00000         0.000000      0.000000         0.000000   \n",
       "75%        0.00000         0.000000      0.000000         0.000000   \n",
       "max        1.00000         1.000000      1.000000         1.000000   \n",
       "\n",
       "       same_srv_rate  ...  logged_in_logged_in  root_shell_0  root_shell_1  \\\n",
       "count   64294.000000  ...         64294.000000  64294.000000   64294.00000   \n",
       "mean        0.997529  ...             0.000016      0.999704       0.00028   \n",
       "std         0.045344  ...             0.003944      0.017188       0.01673   \n",
       "min         0.000000  ...             0.000000      0.000000       0.00000   \n",
       "25%         1.000000  ...             0.000000      1.000000       0.00000   \n",
       "50%         1.000000  ...             0.000000      1.000000       0.00000   \n",
       "75%         1.000000  ...             0.000000      1.000000       0.00000   \n",
       "max         1.000000  ...             1.000000      1.000000       1.00000   \n",
       "\n",
       "       root_shell_root_shell  su_attempted_0  su_attempted_su_attempted  \\\n",
       "count           64294.000000    64294.000000               64294.000000   \n",
       "mean                0.000016        0.999984                   0.000016   \n",
       "std                 0.003944        0.003944                   0.003944   \n",
       "min                 0.000000        0.000000                   0.000000   \n",
       "25%                 0.000000        1.000000                   0.000000   \n",
       "50%                 0.000000        1.000000                   0.000000   \n",
       "75%                 0.000000        1.000000                   0.000000   \n",
       "max                 1.000000        1.000000                   1.000000   \n",
       "\n",
       "       is_host_login_0  is_host_login_is_host_login  is_guest_login_0  \\\n",
       "count     64294.000000                 64294.000000      64294.000000   \n",
       "mean          0.999984                     0.000016          0.999984   \n",
       "std           0.003944                     0.003944          0.003944   \n",
       "min           0.000000                     0.000000          0.000000   \n",
       "25%           1.000000                     0.000000          1.000000   \n",
       "50%           1.000000                     0.000000          1.000000   \n",
       "75%           1.000000                     0.000000          1.000000   \n",
       "max           1.000000                     1.000000          1.000000   \n",
       "\n",
       "       is_guest_login_is_guest_login  \n",
       "count                   64294.000000  \n",
       "mean                        0.000016  \n",
       "std                         0.003944  \n",
       "min                         0.000000  \n",
       "25%                         0.000000  \n",
       "50%                         0.000000  \n",
       "75%                         0.000000  \n",
       "max                         1.000000  \n",
       "\n",
       "[8 rows x 59 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "650e26ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data (First 5 rows):\n",
      "       duration  src_bytes  dst_bytes  count  srv_count\n",
      "61089       0.0      297.0      327.0   26.0       26.0\n",
      "40286       0.0      346.0     3694.0    6.0        7.0\n",
      "50242       0.0      208.0      393.0    8.0       13.0\n",
      "46990       0.0      148.0      427.0    1.0        2.0\n",
      "14217       0.0      310.0      336.0    9.0        9.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Data (First 5 rows):\")\n",
    "print(X_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c876488b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>count</th>\n",
       "      <th>srv_count</th>\n",
       "      <th>serror_rate</th>\n",
       "      <th>srv_serror_rate</th>\n",
       "      <th>rerror_rate</th>\n",
       "      <th>srv_rerror_rate</th>\n",
       "      <th>same_srv_rate</th>\n",
       "      <th>...</th>\n",
       "      <th>logged_in_logged_in</th>\n",
       "      <th>root_shell_0</th>\n",
       "      <th>root_shell_1</th>\n",
       "      <th>root_shell_root_shell</th>\n",
       "      <th>su_attempted_0</th>\n",
       "      <th>su_attempted_su_attempted</th>\n",
       "      <th>is_host_login_0</th>\n",
       "      <th>is_host_login_is_host_login</th>\n",
       "      <th>is_guest_login_0</th>\n",
       "      <th>is_guest_login_is_guest_login</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>64294.000000</td>\n",
       "      <td>64294.000000</td>\n",
       "      <td>6.429400e+04</td>\n",
       "      <td>64294.000000</td>\n",
       "      <td>64294.000000</td>\n",
       "      <td>64294.00000</td>\n",
       "      <td>64294.000000</td>\n",
       "      <td>64294.000000</td>\n",
       "      <td>64294.000000</td>\n",
       "      <td>64294.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>64294.000000</td>\n",
       "      <td>64294.000000</td>\n",
       "      <td>64294.00000</td>\n",
       "      <td>64294.000000</td>\n",
       "      <td>64294.000000</td>\n",
       "      <td>64294.000000</td>\n",
       "      <td>64294.000000</td>\n",
       "      <td>64294.000000</td>\n",
       "      <td>64294.000000</td>\n",
       "      <td>64294.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.266230</td>\n",
       "      <td>2084.757629</td>\n",
       "      <td>4.256075e+03</td>\n",
       "      <td>9.203907</td>\n",
       "      <td>11.691900</td>\n",
       "      <td>0.00445</td>\n",
       "      <td>0.004783</td>\n",
       "      <td>0.085368</td>\n",
       "      <td>0.087672</td>\n",
       "      <td>0.997529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.999704</td>\n",
       "      <td>0.00028</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>0.000016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>162.532963</td>\n",
       "      <td>9826.523839</td>\n",
       "      <td>1.898877e+04</td>\n",
       "      <td>13.219673</td>\n",
       "      <td>11.626554</td>\n",
       "      <td>0.05745</td>\n",
       "      <td>0.056281</td>\n",
       "      <td>0.277118</td>\n",
       "      <td>0.276203</td>\n",
       "      <td>0.045344</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003944</td>\n",
       "      <td>0.017188</td>\n",
       "      <td>0.01673</td>\n",
       "      <td>0.003944</td>\n",
       "      <td>0.003944</td>\n",
       "      <td>0.003944</td>\n",
       "      <td>0.003944</td>\n",
       "      <td>0.003944</td>\n",
       "      <td>0.003944</td>\n",
       "      <td>0.003944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>4.730000e+02</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>243.000000</td>\n",
       "      <td>1.502000e+03</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>306.000000</td>\n",
       "      <td>4.361000e+03</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>41065.000000</td>\n",
       "      <td>54540.000000</td>\n",
       "      <td>3.916592e+06</td>\n",
       "      <td>511.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           duration     src_bytes     dst_bytes         count     srv_count  \\\n",
       "count  64294.000000  64294.000000  6.429400e+04  64294.000000  64294.000000   \n",
       "mean       1.266230   2084.757629  4.256075e+03      9.203907     11.691900   \n",
       "std      162.532963   9826.523839  1.898877e+04     13.219673     11.626554   \n",
       "min        0.000000      0.000000  0.000000e+00      0.000000      0.000000   \n",
       "25%        0.000000    210.000000  4.730000e+02      2.000000      3.000000   \n",
       "50%        0.000000    243.000000  1.502000e+03      6.000000      8.000000   \n",
       "75%        0.000000    306.000000  4.361000e+03     13.000000     17.000000   \n",
       "max    41065.000000  54540.000000  3.916592e+06    511.000000    109.000000   \n",
       "\n",
       "       serror_rate  srv_serror_rate   rerror_rate  srv_rerror_rate  \\\n",
       "count  64294.00000     64294.000000  64294.000000     64294.000000   \n",
       "mean       0.00445         0.004783      0.085368         0.087672   \n",
       "std        0.05745         0.056281      0.277118         0.276203   \n",
       "min        0.00000         0.000000      0.000000         0.000000   \n",
       "25%        0.00000         0.000000      0.000000         0.000000   \n",
       "50%        0.00000         0.000000      0.000000         0.000000   \n",
       "75%        0.00000         0.000000      0.000000         0.000000   \n",
       "max        1.00000         1.000000      1.000000         1.000000   \n",
       "\n",
       "       same_srv_rate  ...  logged_in_logged_in  root_shell_0  root_shell_1  \\\n",
       "count   64294.000000  ...         64294.000000  64294.000000   64294.00000   \n",
       "mean        0.997529  ...             0.000016      0.999704       0.00028   \n",
       "std         0.045344  ...             0.003944      0.017188       0.01673   \n",
       "min         0.000000  ...             0.000000      0.000000       0.00000   \n",
       "25%         1.000000  ...             0.000000      1.000000       0.00000   \n",
       "50%         1.000000  ...             0.000000      1.000000       0.00000   \n",
       "75%         1.000000  ...             0.000000      1.000000       0.00000   \n",
       "max         1.000000  ...             1.000000      1.000000       1.00000   \n",
       "\n",
       "       root_shell_root_shell  su_attempted_0  su_attempted_su_attempted  \\\n",
       "count           64294.000000    64294.000000               64294.000000   \n",
       "mean                0.000016        0.999984                   0.000016   \n",
       "std                 0.003944        0.003944                   0.003944   \n",
       "min                 0.000000        0.000000                   0.000000   \n",
       "25%                 0.000000        1.000000                   0.000000   \n",
       "50%                 0.000000        1.000000                   0.000000   \n",
       "75%                 0.000000        1.000000                   0.000000   \n",
       "max                 1.000000        1.000000                   1.000000   \n",
       "\n",
       "       is_host_login_0  is_host_login_is_host_login  is_guest_login_0  \\\n",
       "count     64294.000000                 64294.000000      64294.000000   \n",
       "mean          0.999984                     0.000016          0.999984   \n",
       "std           0.003944                     0.003944          0.003944   \n",
       "min           0.000000                     0.000000          0.000000   \n",
       "25%           1.000000                     0.000000          1.000000   \n",
       "50%           1.000000                     0.000000          1.000000   \n",
       "75%           1.000000                     0.000000          1.000000   \n",
       "max           1.000000                     1.000000          1.000000   \n",
       "\n",
       "       is_guest_login_is_guest_login  \n",
       "count                   64294.000000  \n",
       "mean                        0.000016  \n",
       "std                         0.003944  \n",
       "min                         0.000000  \n",
       "25%                         0.000000  \n",
       "50%                         0.000000  \n",
       "75%                         0.000000  \n",
       "max                         1.000000  \n",
       "\n",
       "[8 rows x 59 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "737bce51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>num_root</th>\n",
       "      <th>num_file_creations</th>\n",
       "      <th>num_shells</th>\n",
       "      <th>num_access_files</th>\n",
       "      <th>num_outbound_cmds</th>\n",
       "      <th>...</th>\n",
       "      <th>logged_in_logged_in</th>\n",
       "      <th>root_shell_0</th>\n",
       "      <th>root_shell_1</th>\n",
       "      <th>root_shell_root_shell</th>\n",
       "      <th>su_attempted_0</th>\n",
       "      <th>su_attempted_su_attempted</th>\n",
       "      <th>is_host_login_0</th>\n",
       "      <th>is_host_login_is_host_login</th>\n",
       "      <th>is_guest_login_0</th>\n",
       "      <th>is_guest_login_is_guest_login</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>num_failed_logins</td>\n",
       "      <td>num_compromised</td>\n",
       "      <td>num_root</td>\n",
       "      <td>num_file_creations</td>\n",
       "      <td>num_shells</td>\n",
       "      <td>num_access_files</td>\n",
       "      <td>num_outbound_cmds</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>5450.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>486.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>1337.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>1337.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration  src_bytes  dst_bytes  num_failed_logins  num_compromised  \\\n",
       "0       0.0        0.0        0.0  num_failed_logins  num_compromised   \n",
       "1       0.0      181.0     5450.0                  0                0   \n",
       "2       0.0      239.0      486.0                  0                0   \n",
       "3       0.0      235.0     1337.0                  0                0   \n",
       "4       0.0      219.0     1337.0                  0                0   \n",
       "\n",
       "   num_root  num_file_creations  num_shells  num_access_files  \\\n",
       "0  num_root  num_file_creations  num_shells  num_access_files   \n",
       "1         0                   0           0                 0   \n",
       "2         0                   0           0                 0   \n",
       "3         0                   0           0                 0   \n",
       "4         0                   0           0                 0   \n",
       "\n",
       "   num_outbound_cmds  ...  logged_in_logged_in  root_shell_0  root_shell_1  \\\n",
       "0  num_outbound_cmds  ...                    1             0             0   \n",
       "1                  0  ...                    0             1             0   \n",
       "2                  0  ...                    0             1             0   \n",
       "3                  0  ...                    0             1             0   \n",
       "4                  0  ...                    0             1             0   \n",
       "\n",
       "   root_shell_root_shell  su_attempted_0  su_attempted_su_attempted  \\\n",
       "0                      1               0                          1   \n",
       "1                      0               1                          0   \n",
       "2                      0               1                          0   \n",
       "3                      0               1                          0   \n",
       "4                      0               1                          0   \n",
       "\n",
       "   is_host_login_0  is_host_login_is_host_login  is_guest_login_0  \\\n",
       "0                0                            1                 0   \n",
       "1                1                            0                 1   \n",
       "2                1                            0                 1   \n",
       "3                1                            0                 1   \n",
       "4                1                            0                 1   \n",
       "\n",
       "   is_guest_login_is_guest_login  \n",
       "0                              1  \n",
       "1                              0  \n",
       "2                              0  \n",
       "3                              0  \n",
       "4                              0  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "caf3d62d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'num_failed_logins'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2696\\3727118804.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;31m# Step 6: Initialize and train the IsolationForest model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mIsolationForest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;31m# Step 7: Make predictions using the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_iforest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    256\u001b[0m             \u001b[0mFitted\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m         \"\"\"\n\u001b[1;32m--> 258\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    259\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m             \u001b[1;31m# Pre-sort indices to avoid that each individual tree of the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    564\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 566\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    567\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    568\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    744\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    745\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 746\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    747\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    748\u001b[0m                 raise ValueError(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2062\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2063\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2064\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2065\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2066\u001b[0m     def __array_wrap__(\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'num_failed_logins'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "dtype = {\n",
    "    'duration': float,\n",
    "    'protocol_type': str,\n",
    "    'service': str,\n",
    "    'flag': str,\n",
    "    'src_bytes': float,\n",
    "    'dst_bytes': float,\n",
    "    'land': str,  \n",
    "    'wrong_fragment': str,\n",
    "    'urgent': str, \n",
    "    'hot': str,  \n",
    "    'num_failed_logins': float,  \n",
    "    'logged_in': str,  \n",
    "    'num_compromised': float,  \n",
    "    'root_shell': str,  \n",
    "    'su_attempted': str,  \n",
    "    'num_root': float,  \n",
    "    'num_file_creations': float,  \n",
    "    'num_shells': str,  \n",
    "    'num_access_files': float,  \n",
    "    'num_outbound_cmds': float,  \n",
    "    'is_host_login': str,  \n",
    "    'is_guest_login': str,  \n",
    "    'count': float,  \n",
    "    'srv_count': float,  \n",
    "    'serror_rate': float,  \n",
    "    'srv_serror_rate': float,  \n",
    "    'rerror_rate': float,  \n",
    "    'srv_rerror_rate': float,  \n",
    "    'same_srv_rate': float,  \n",
    "    'diff_srv_rate': float,  \n",
    "    'srv_diff_host_rate': float,  \n",
    "    'dst_host_count': float,  \n",
    "    'dst_host_srv_count': float,  \n",
    "    'dst_host_same_srv_rate': float,  \n",
    "    'dst_host_diff_srv_rate': float,  \n",
    "    'dst_host_same_src_port_rate': float,  \n",
    "    'dst_host_srv_diff_host_rate': float,  \n",
    "    'dst_host_serror_rate': float,  \n",
    "    'dst_host_srv_serror_rate': float,  \n",
    "    'dst_host_rerror_rate': float,  \n",
    "    'dst_host_srv_rerror_rate': float,  \n",
    "    'label': str  \n",
    "}\n",
    "\n",
    "column_names = [\n",
    "    'duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes',\n",
    "    'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins',\n",
    "    'logged_in', 'num_compromised', 'root_shell', 'su_attempted', 'num_root',\n",
    "    'num_file_creations', 'num_shells', 'num_access_files', 'num_outbound_cmds',\n",
    "    'is_host_login', 'is_guest_login', 'count', 'srv_count', 'serror_rate',\n",
    "    'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate',\n",
    "    'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count',\n",
    "    'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',\n",
    "    'dst_host_srv_diff_host_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate',\n",
    "    'dst_host_rerror_rate', 'dst_host_srv_rerror_rate', 'label'\n",
    "]\n",
    "\n",
    "dataset_path = 'kddcup.data_10_percent_corrected.csv'  # Replace with actual path\n",
    "data = pd.read_csv(dataset_path, names=column_names, header=None, low_memory=False)\n",
    "\n",
    "# Step 2: Convert categorical columns to numeric using one-hot encoding\n",
    "categorical_columns = ['protocol_type', 'service', 'flag', 'land', 'wrong_fragment', 'urgent', 'hot', 'logged_in', 'root_shell', 'su_attempted', 'is_host_login', 'is_guest_login']\n",
    "data = pd.get_dummies(data, columns=categorical_columns)\n",
    "\n",
    "# Step 3: Handle missing values or conversion issues\n",
    "numeric_columns = ['duration', 'src_bytes', 'dst_bytes', 'count', 'srv_count', 'serror_rate', 'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'dst_host_rerror_rate', 'dst_host_srv_rerror_rate']\n",
    "data[numeric_columns] = data[numeric_columns].apply(pd.to_numeric, errors='coerce')\n",
    "data.fillna(0, inplace=True)\n",
    "\n",
    "# Step 4: Split the dataset into features (X) and target (y)\n",
    "X = data.drop(columns=['label'])\n",
    "y = data['label']\n",
    "\n",
    "# Step 5: Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Step 6: Initialize and train the IsolationForest model\n",
    "model = IsolationForest()\n",
    "model.fit(X_train)\n",
    "\n",
    "# Step 7: Make predictions using the model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Since IsolationForest returns -1 for anomalies and 1 for normal data, we will adjust labels:\n",
    "y_pred = [1 if pred == -1 else 0 for pred in y_pred]\n",
    "\n",
    "# Step 8: Evaluate the model performance using confusion matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6417c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
